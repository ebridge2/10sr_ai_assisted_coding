(rules:testing)=
# Testing & Validation

Testing becomes even more critical when AI generates implementation code. The speed at which AI can produce code creates a dangerous illusion: you have working software when you actually have plausible-looking code that may fail in subtle ways. AI models are prone to specific failure modes in testing contexts that human developers rarely exhibit. They will modify tests to pass rather than fixing the underlying code. They will generate tests that check implementation details rather than behavior. They will claim success based on superficial validation while missing fundamental correctness issues.

The two rules in this section establish practices for making testing your primary defense against these failure modes. These practices transform testing from a validation step into a specification and guidance mechanism. When you leverage tests early and often in your development cycle, you give AI concrete targets that are harder to misinterpret than natural language requirements. When you build infrastructure early, you catch integration problems before they compound. When you use AI to explore edge cases, you find failure modes you might have missed, but you must verify the tests themselves are actually testing what matters.
